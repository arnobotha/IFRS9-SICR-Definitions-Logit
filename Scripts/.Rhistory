source(paste0(path_cust,'DelinqM.R'))
#rm(list=ls())
# - Define the parameters
p.k <- 3
p.s <- 2
p.d <- 2
# - Define SICR-definition label
SICR_label <- "2b(i)"
# - Graphing parameters
chosenFont <- "Cambria"
dpi <- 250
# - Field names
stratifiers <- c("SICR_target_event", "Date") # Must at least include target variable used in graphing event rate
targetVar <- "SICR_target_event"
timeVar <- "Date"
# - Subsampling & resampling parameters
smp_size <- 1000000 # fixed size of downsampled set
train_prop <- 0.7 # sampling fraction for resampling scheme
# - Confirm prepared data after exclusions is loaded into memory
if(!exists('datCredit_real')) unpack.ffdf(paste0(genPath,"creditdata_final4c"), tempPath)
# - Retain fields based on logit-model corresponding to this definition
varKeep <- c("LoanID", "Date", "Counter",
# Delinquency-theme inputs
"g0_Delinq", "TimeInPerfSpell", "slc_acct_roll_ever_24_imputed", "slc_acct_arr_dir_3",
# Credit-themed inputs
"BalanceToTerm", "InterestRate_Margin", "pmnt_method_grp", "Receipt_InfLog",
"slc_acct_pre_lim_perc_imputed", "PD_ratio"
)
datSICR <- subset(datCredit_real, select=varKeep)
# - Cleanup (Memory optimisation)
rm(datCredit_real); gc()
# - Create the SICR-definition based on the parameters [Time-consuming step]
datSICR[, SICR_def := SICR_flag(g0_Delinq, d=p.d, s=p.s), by=list(LoanID)]; gc()
# - Look ahead (over k periods) and assign the SICR-event appropriately for each record
datSICR[, SICR_target := shift(SICR_def, type='lead', n=p.k), by=list(LoanID)]
# - Discard observations where target has NA, implying insufficient history
datSICR <- subset(datSICR, !is.na(SICR_target))
# - Check the event rate of each class | RECORD-LEVEL
table(datSICR$SICR_target) %>% prop.table() # 99.78% Non-SICR vs 0.22% SICR
# - Convert the target variable to a categorical variable for modelling
datSICR[, SICR_target := factor(SICR_target)]; gc()
# - Prepare for resamling scheme
datSICR[, ind := 1:.N]
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "datSICR_", SICR_label), datSICR)
# -- Creating SICR-samples
# - Confirm SICR-dataset is loaded into memory (useful step during interactive execution)
if (!exists('datSICR')) unpack.ffdf(paste0(genPath,"datSICR_", SICR_label), tempPath)
# - Downsample data into a fixed subsample before implementing resampling scheme
smp_size <- 250000; smp_percentage <- smp_size/nrow(datSICR)
set.seed(1)
datSICR_smp <- datSICR %>% group_by(SICR_target, Date) %>% slice_sample(prop=smp_percentage) %>% as.data.table()
# - Join the macros on the filtered dataset to avoid memory constraints
datSICR_smp <- merge_macro_info(input_dat = datSICR_smp)
# - Retain fields based on logit-model corresponding to this definition
varKeep <- c("LoanID", "Date", "Counter", "SICR_target", "ind", "SICR_def",
# Delinquency-theme inputs
"g0_Delinq", "TimeInPerfSpell", "slc_acct_roll_ever_24_imputed", "slc_acct_arr_dir_3",
# Credit-themed inputs
"BalanceToTerm", "InterestRate_Margin", "pmnt_method_grp", "Receipt_InfLog",
"slc_acct_pre_lim_perc_imputed", "PD_ratio",
# Macroeconomic-themed inputs
"M_Repo_Rate", "M_Inflation_Growth",
"M_DTI_Growth", "M_DTI_Growth_12", "M_Emp_Growth"
)
datSICR_smp <- subset(datSICR_smp, select=varKeep)
# - Implement resampling scheme using 70% as sampling fraction
set.seed(1)
datSICR_train <- datSICR_smp %>% group_by(SICR_target, Date) %>% slice_sample(prop=0.7) %>% mutate(Sample="Train") %>% as.data.table()
datSICR_valid <- subset(datSICR_smp, !(ind %in% datSICR_train$ind)) %>% mutate(Sample="Validation")
# - Check representativeness | dataset-level proportions should be similar
table(datSICR_smp$SICR_target) %>% prop.table()
table(datSICR_train$SICR_target) %>% prop.table()
table(datSICR_valid$SICR_target) %>% prop.table()
### RESULTS: Conforms to original proportions, representativeness confirmed
# - cleanup
rm(datSICR); gc()
# - Define model form
inputs_chosen <- SICR_target ~ BalanceToTerm + InterestRate_Margin + Receipt_InfLog + pmnt_method_grp + #PD_ratio +
slc_acct_pre_lim_perc_imputed + TimeInPerfSpell + g0_Delinq + slc_acct_arr_dir_3 +
slc_acct_roll_ever_24_imputed + M_Repo_Rate + M_Inflation_Growth + M_DTI_Growth +
M_DTI_Growth_12 + M_Emp_Growth
# - Save model formula
# - Fit final logit model
logit_model_chosen <- glm(inputs_chosen, data=datSICR_train, family="binomial")
summary(logit_model_chosen)
# - Define model form
inputs_chosen <- SICR_target ~ BalanceToTerm + InterestRate_Margin + Receipt_InfLog + pmnt_method_grp + PD_ratio +
slc_acct_pre_lim_perc_imputed + TimeInPerfSpell + g0_Delinq + slc_acct_arr_dir_3 +
slc_acct_roll_ever_24_imputed + M_Repo_Rate + M_Inflation_Growth + M_DTI_Growth +
M_DTI_Growth_12 + M_Emp_Growth
# - Save model formula
pack.ffdf(paste0(genObjPath, "SICR_", SICR_label, "_formula_undummified"), inputs_chosen)
# - Fit final logit model
logit_model_chosen <- glm(inputs_chosen, data=datSICR_train, family="binomial")
summary(logit_model_chosen)
# - Score data using fitted model
datSICR_train[, Prob_chosen_2b_i := predict(logit_model_chosen, newdata = datSICR_train, type="response")]
datSICR_valid[, Prob_chosen_2b_i := predict(logit_model_chosen, newdata = datSICR_valid, type="response")]
datSICR_smp[, ExpProb := predict(logit_model_chosen, newdata = datSICR_smp, type="response")]
# - Compute the AUC
auc(datSICR_train$SICR_target, datSICR_train$Prob_chosen_2b_i) # 97.20%
auc(datSICR_valid$SICR_target, datSICR_valid$Prob_chosen_2b_i) # 97.15%
auc(datSICR_smp$SICR_target, datSICR_smp$ExpProb) # 97.18%
# --- 5.2 Plot the density of the class probabilities
# - Graphing parameters
labels.v <- c(bquote(italic(C)[0]),
bquote(italic(C)[1]))
# - Plot double density across both classes
ggplot( data=datSICR_valid, aes(x=Prob_chosen_2b_i)) + theme_bw() +
geom_histogram(aes(y= ..density.., colour=factor(SICR_target), fill=factor(SICR_target)), alpha=0.7,
bins=2*datSICR_valid[,.N]^(1/3), position="identity") + # using Rice's rule
geom_density(aes(colour=factor(SICR_target), fill=factor(SICR_target)), size=0.8, alpha=0.5) +
labs(x="Class probability", y="Density") +
theme(legend.position="bottom", text=element_text(family=chosenFont)) +
scale_color_brewer(palette="Dark2", name="Class", labels=labels.v) +
scale_fill_brewer(palette="Set2", name="Class", labels=labels.v) +
scale_x_continuous(breaks=pretty_breaks(), label=percent)
# --- 5.3 Find optimal points (c) according to several measures using the training data
# - Set misclassification costs for false positives (FP) and false negatives (FN) respectively
# These are only applicable to cost-sensitive measures later
cost_fp <- 1; cost_fn <- 6
cost_ratio <- cost_fn/cost_fp
# Experimented with [cost_fn] given the underprediction-problem outlined in section 6.3
# Candidates include 40, 10, 6, 7, 8 ; all of whom gave very high overprediction (decreasingly so for lower cost-values).
#  AUC-values remained between 80-83% once discretised.
# Misclassification cost of 8 was propagated to definitions 1a(ii) and 1a(iii)
# Upon this, it was found that the resulting cut-off leads to severe overprediction
# Accordingly, an analysis was conducted to investigate the use of 7 or 6 as the misclassification cost
# The analysis revealed that as k increases, higher misclassification costs result in overprediction
# Since a constant misclassification cost is required over all the definitions, it was decided that 6 yields a good balance across all definitions
# Therefore, final value selected: 6
# - Find optimal cut-offs according to the Generalised Youden's Index measures
# This requires significant memory, which cannot be handled by the current size of the training dataset
optimal.cutpoint.GenYouden <- Gen_Youd_Ind(logit_model_chosen, datSICR_valid, "SICR_target", cost_ratio)
# - Set final cut-off
(logistic_cutoff <- optimal.cutpoint.GenYouden$cutoff)
datSICR_train[, Pred_chosen_2b_i := ifelse(Prob_chosen_2b_i >= logistic_cutoff, 1, 0)]
datSICR_valid[, Pred_chosen_2b_i := ifelse(Prob_chosen_2b_i >= logistic_cutoff, 1, 0)]
datSICR_smp[, ExpDisc := ifelse(ExpProb >= logistic_cutoff, 1, 0)]
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "datSICR_smp_", SICR_label), datSICR_smp)
pack.ffdf(paste0(genPath, "datSICR_valid_", SICR_label), datSICR_valid)
# ------- 6. ROC-Analysis and overall model assessment
# --- 6.1 ROC-analysis using pROC-package
# See https://rviews.rstudio.com/2019/03/01/some-r-packages-for-roc-curves/
# Mixed with https://cran.r-project.org/web/packages/ROCit/vignettes/my-vignette.html
# - Set confidence level for bootstrapping the uncertainty of AUC/Gini-measures
alpha <- 0.05
# - Confirm SICR-dataset is loaded into memory (useful step during interactive execution)
if (!exists('datSICR_valid')) unpack.ffdf(paste0(genPath,"datSICR_valid_", SICR_label), tempPath)
# - Create ROC-object | probabilities vs discrete lables
pROC_obj_chosena <- roc(formula= SICR_target~Pred_chosen_2b_i, data=datSICR_valid, ci.method="bootstrap", ci=T, conf.level = 1-alpha, percent=T)
pROC_obj_chosenb <- roc(formula= SICR_target~Prob_chosen_2b_i, data=datSICR_valid, ci.method="bootstrap", ci=T, conf.level = 1-alpha, percent=T)
# --- 6.2 Compute other performance measures
# - Standard deviation
# used to represent the stability of the SICR-definition
datSICR_valid[, SICR_predict_variance := sd(Prob_chosen_2b_i), by=list(LoanID)]
standard_deviation <- round(mean(datSICR_valid$SICR_predict_variance, na.rm=T)*100, digits=1)
# - Confusion matrix
conf_mat <- datSICR_valid[, list(TN=sum(ifelse(SICR_target == 0 & Pred_chosen_2b_i == 0, 1, 0)),
FP=sum(ifelse(SICR_target == 0 & Pred_chosen_2b_i == 1, 1, 0)),
TP=sum(ifelse(SICR_target == 1 & Pred_chosen_2b_i == 1, 1, 0)),
FN=sum(ifelse(SICR_target == 1 & Pred_chosen_2b_i == 0, 1, 0)))]
conf_mat[, positives := TP + FN]
conf_mat[, negatives := TN + FP]
# - Sensitivity and specificity (true positive rate and true negative rate)
# True positive rate
(true_positive_rate <- round(conf_mat$TP/conf_mat$positives*100, digits=1))
# True negative rate
(true_negative_rate <- round(conf_mat$TN/conf_mat$negatives*100, digits=1))
# --- 6.3 Calculate SICR-incidence
# - Confirm SICR-dataset is loaded into memory (useful step during interactive execution)
if (!exists('datSICR_smp')) unpack.ffdf(paste0(genPath,"datSICR_smp_", SICR_label), tempPath)
if (!exists('logistic_cutoff')) logistic_cutoff <- 0.07637852
# A few things of concern:
# 1) Volatility in event rates due to relatively low sampling volumes in validation set
# 2) 0-counts over 20006-2007 periods using discretised output [Pred_chosen_2b_i]
# 3) Trend of "underprediction" (expected red line consistently being underneath actual green line). "overprediction" would have been
#   more palatable given our preference for greater sensitivity (T^+ rate) over low false positive rate under IFRS 9
#   But this largely comes down to cut-off selection when dealing with probabilistic classifiers ..
#   In fact, underprediction would have been a good argument to adjust cut-off accordingly, had we been in a Technical Committee
# As such, the following changes have been made:
# 1) Switched to subsampled dataset (250k) for reporting purposes, instead of the too-small validation set
# 2) Included the probabilistic output, which we'll know will be much closer to the green line
# 3) renamed some fields accordingly
datSICR_graph <- rbind(datSICR_smp[, list(LoanID, Date, SICR_def, SICR_events=SICR_target , Type="a_Actual")],
datSICR_smp[, list(LoanID, Date, SICR_def, SICR_events=ExpProb, Type="b_Modelled_prob")],
datSICR_smp[, list(LoanID, Date, SICR_def, SICR_events=ExpDisc, Type="c_Modelled_disc")])
# - Transform factor back to numeric variables for aggregation purposes
datSICR_graph[, SICR_events := as.numeric(levels(SICR_events))[SICR_events]]
# - Aggregate to monthly level and observe up to given point
SICR_StartDte <- min(datSICR_smp$Date, na.rm=T)
SICR_EndDte <- max(datSICR_smp$Date, na.rm=T)
port.aggr <- datSICR_graph[SICR_def==0, list(EventRate = sum(SICR_events, na.rm=T)/.N, AtRisk = .N),
by=list(Type, Date)][Date >= SICR_StartDte & Date <= SICR_EndDte,] %>% setkey(Type,Date)
# - Aesthetics engineering
port.aggr[, Facet_label := paste0("SICR-definition ", SICR_label)]
# - Calculate MAE over time by line graph type in summarising differences amongst line graphs
port.aggr2 <- port.aggr %>% pivot_wider(id_cols = c(Date, Type), names_from = c(Type), values_from = c(EventRate))
(diag.Act_ExpProb <- mean(abs(port.aggr2$a_Actual - port.aggr2$b_Modelled_prob)) * 100)
(diag.Act_ExpDisc <- mean(abs(port.aggr2$a_Actual - port.aggr2$c_Modelled_disc)) * 100)
# - Calculate standard deviation of these processes
stdev_SICR_Act <- sd(port.aggr2$a_Actual, na.rm=T)
stdev_SICR_ExpProb <- sd(port.aggr2$b_Modelled_prob, na.rm=T)
stdev_SICR_ExpDisc <- sd(port.aggr2$c_Modelled_disc, na.rm=T)
# - Calculate so-called risk prudence degree to measure the degree to which the discrete expected SICR- rate exceeds the actual SICR-rate
overPredictDegree_prob <- sum(port.aggr2$b_Modelled_prob>=port.aggr2$a_Actual)/length(port.aggr2$b_Modelled_prob)
overPredictDegree_disc <- sum(port.aggr2$c_Modelled_disc>=port.aggr2$a_Actual)/length(port.aggr2$c_Modelled_disc)
# - Graphing parameters
col.v <- brewer.pal(5, "Dark2")
label.v <- c("a_Actual"=bquote(italic(A[t])*": Actual"),
"b_Modelled_prob"=bquote(italic(B[t])*": Expected"),
"c_Modelled_disc"=bquote(italic(C[t])*": Expected-discrete ("*italic(c)==.(round(logistic_cutoff*100,digits=1))*"%)"))
# - Create graph
(g <- ggplot(port.aggr, aes(x=Date, y=EventRate, group=Type)) + theme_minimal() +
labs(x="Reporting date (months)", y="Conditional SICR-rate (%)") +
theme(text=element_text(family=chosenFont),legend.position = "bottom",
axis.text.x=element_text(angle=90),
strip.background=element_rect(fill="snow2", colour="snow2"),
strip.text=element_text(size=8, colour="gray50"), strip.text.y.right=element_text(angle=90)) +
# main line graph with overlaid points
geom_line(aes(colour=Type, linetype=Type), size=0.1) +
geom_point(aes(colour=Type, shape=Type), size=0.6) +
#annotations
annotate(geom="text", x=as.Date("2015-12-31"), y=port.aggr[Date >= "2012-12-31" & Type=="a_Actual", mean(EventRate)]*6,
label=paste0("'MAE between '*italic(A[t])*' and '*italic(B[t])*': ", sprintf("%.2f", diag.Act_ExpProb),"%'"),
family=chosenFont, size=3, parse=T) +
annotate(geom="text", x=as.Date("2015-12-31"), y=port.aggr[Date >= "2012-12-31" & Type=="a_Actual", mean(EventRate)]*5.7,
label=paste0("'MAE between '*italic(A[t])*' and '*italic(C[t])*': ", sprintf("%.2f", diag.Act_ExpDisc),"%'"),
family=chosenFont, size=3, parse=T) +
# facets & scale options
facet_grid(Facet_label ~ .) +
scale_colour_manual(name="", values=col.v, labels=label.v) +
scale_shape_discrete(name="", labels=label.v) + scale_linetype_discrete(name="", labels=label.v) +
#guides(colour=guide_legend(nrow=2,byrow=T)) +
scale_y_continuous(breaks=pretty_breaks(), label=percent) +
scale_x_date(date_breaks=paste0(6, " month"), date_labels = "%b %Y"))
# - Save graph
ggsave(g, file=paste0(genFigPath, "TimeGraph_SICR-Incidence_ActExp", SICR_label,".png"), width=1200/dpi, height=1000/dpi, dpi=dpi, bg="white")
# - Cleanup
rm(datSICR_graph, port.aggr, port.aggr2); gc()
# ------- 7. Pack objects to disk
# --- 7.1 Performance measures
performance_measures_2b_i <- data.frame(SICR_definition = paste0(SICR_label, "_logit"),
d=p.d, s=p.s, k=p.k,
AUC_prob = c(round(pROC_obj_chosenb$auc,digits=1)),
CI_lower_prob = c(round(pROC_obj_chosenb$ci[1],digits=2)),
CI_upper_prob = c(round(pROC_obj_chosenb$ci[3],digits=2)),
cut_off = c(round(logistic_cutoff*100,digits=1)),
cut_off_raw = logistic_cutoff,
AUC_discrete = c(round(pROC_obj_chosena$auc,digits=1)),
CI_lower_discrete = c(round(pROC_obj_chosena$ci[1],digits=2)),
CI_upper_discrete = c(round(pROC_obj_chosena$ci[3],digits=2)),
std_dev = c(standard_deviation),
tpr = c(true_positive_rate),
tnr = c(true_negative_rate),
MAE_Act_ExpDisc = round(diag.Act_ExpDisc, digits=2),
MAE_Act_ExpProb = round(diag.Act_ExpProb, digits=2),
std_dev_SICR_rate_Act = round(stdev_SICR_Act, digits=4),
std_dev_SICR_rate_ExpDisc = round(stdev_SICR_ExpDisc, digits=4),
std_dev_SICR_rate_ExpProb = round(stdev_SICR_ExpProb, digits=4),
OverPredict_ExpDisc = round(overPredictDegree_disc,digits=5),
OverPredict_ExpProb = round(overPredictDegree_prob,digits=5),
stringsAsFactors = FALSE)
pack.ffdf(paste0(genPath, "performance_measures_", SICR_label), performance_measures_2b_i); gc()
# --- 7.2 Trained logit model
pack.ffdf(paste0(genPath, "logit_model_", SICR_label), logit_model_chosen); gc()
# =================================== SETUP ====================================
# Preparing runtime environment and setting parameters
# ------------------------------------------------------------------------------
# PROJECT TITLE: Dynamic SICR-research
# SCRIPT AUTHOR(S): Esmerelda Oberholzer, Dr Arno Botha
# DESCRIPTION:
# This script installs and loads various libraries and packages, compiles all
# custom functions, and set requisite parameters.
# The versions of the packages installed are provided in the README-file.
# ------------------------------------------------------------------------------
# -- Inputs:
#   - 0a.Custom_Functions.R | Custom function definitions and helper functions
#   - 0b.findOptimalCutoff.R | Custom functions to aid threshold-selection for logit-models
#   - DelinqM.R | Delinquency measures and related functions
# ==============================================================================
# --------------------------------- PACKAGES -----------------------------------
# ------ Install and load packages
# - data access and big data management
require(haven) # for SAS imports
require(ETLUtils)
require(ffbase)
require(ff)
require(writexl)
#require(arrow)
tempPath <- "C:/TempData"; options("fftempdir"=tempPath)
# - for data wrangling
require(tidyr)
require(dplyr)
require(data.table)
require(lubridate)
require(readr)
require(bit64) # for very big numeric values
require(stringr) # common string operations, e.g., str_pad
# - for analyses
require(Hmisc) # for describe()
require(moments) # for using skewness() function
#for plots
require(ggplot2)
require(scales)
require(ggthemes)
require(extrafont) #remotes::install_version("Rttf2pt1", version = "1.3.8"); Sys.setenv(R_GSCMD="C:/Program Files/gs/gs9.55.0/bin/gswin32c.exe"); font_import(); loadfonts(); loadfonts(device="win")
require(RColorBrewer)
require(gridExtra)
#for modelling
require(car)
require(prediction)
require(MASS) # for stepAIC() for stepwise regression
require(e1071) # for SVM-technique
require(mlr) # for parallelized SMV-technique and associated tuning tools
require(parallelMap); require(parallel) # for multithreaded SVM-tuning using the mlr-package
require(pROC); require(ROCR) # both for conducting ROC-analyses
require(OptimalCutpoints)
require(DEoptimR)
# for explainability measures
require(DALEX)
require(ranger)
require(fastshap)
# --------------------------------- GENERAL ------------------------------------
# ------ Parametrisation
# - general R options
options(scipen=999) # Suppress showing scientific notation
# - Parameters used in calculating delinquency measures
sc.Thres <- 0.9; # repayment ratio - g1
d <- 3 # default threshold for g0/g1-measures of delinquency (payments in arrears)
k <- 6 # Probation period
# -- Path variables | General
# - Common path for saving big data objects
genPath <- "C:/Data/Dynamic-SICR_Data/"
# - Common path for importing raw data
genRawPath <- "C:/Data/"
# -- Path variables | User-dependent
if (Sys.getenv("USERNAME") == "WRQ") {
# - Custom path where R-scripts are saved
path_cust <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/WRQ/OneDrive - FRG/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Figures/"
} else if (Sys.getenv("USERNAME") == "Arno Botha") {
# - Custom path where R-scripts are saved
path_cust <- "E:/WorkLife/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "E:/WorkLife/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "E:/WorkLife/Analytix/Research/Dynamic-SICR/IFRS9-SICR-Definitions-Logit/Figures/"
# - Common path for saving big data objects
genPath <- "E:/DataDump/FNB SLC/Dynamic-SICR_Data/"
# - Common path for importing raw data
genRawPath <- "E:/DataDump/FNB SLC/"
} else if (Sys.getenv("USERNAME") == "f5361079") {
# - Custom path where R-scripts are saved
# - Custom path where R-scripts are saved
path_cust <- "C:/Users/F5361079/GitHub/IFRS9-SICR-Definitions-Logit/Scripts/"
# - Common path for storing important R-objects as back-up
genObjPath <- "C:/Users/F5361079/GitHub/IFRS9-SICR-Definitions-Logit/Objects/"
# - Common path for saving important analytics (e.g., sampling)
genFigPath <- "C:/Users/F5361079/GitHub/IFRS9-SICR-Definitions-Logit/Figures/"
} else {
stop("User-specific paths not set for current user: ", Sys.getenv("USERNAME"), ". Please fix in Setup script (0.Setup.R) before continuing")
}
# ----------------------------- CUSTOM FUNCTIONS -------------------------------
# ------ Custom function definitions
# - Load all custom functions defined in a separate R-script
source(paste0(path_cust,"0a.Custom_Functions.R"))
# - Compile threshold-selection function for transforming a probabilistic logit-model
# into a discrete classifier
source(paste0(path_cust,"0b.findOptimalCutoff.R"))
# - Compile Delinquency Calculation Functions (CD, MD/DoD)
source(paste0(path_cust,'DelinqM.R'))
#rm(list=ls())
# ------ 0. Setup/parameter definition
# -- Parameters used in the SICR-definition
# k: - outcome period
# s: - number of consecutive payments (stickiness)
# d: - delinquency threshold
# - Define the parameters
p.k <- 9
p.s <- 1
p.d <- 2
# - Define SICR-definition label
SICR_label <- "2a(iii)"
# - Graphing parameters
chosenFont <- "Cambria"
dpi <- 250
# - Field names
stratifiers <- c("SICR_target_event", "Date") # Must at least include target variable used in graphing event rate
targetVar <- "SICR_target_event"
timeVar <- "Date"
# - Subsampling & resampling parameters
smp_size <- 1000000 # fixed size of downsampled set
train_prop <- 0.7 # sampling fraction for resampling scheme
# --- 5.1 Final logit model with stabilized input variables across all the definitions
# - Confirm prepared data after exclusions is loaded into memory
if(!exists('datCredit_real')) unpack.ffdf(paste0(genPath,"creditdata_final4c"), tempPath)
# - Retain fields based on logit-model corresponding to this definition
varKeep <- c("LoanID", "Date", "Counter",
# Delinquency-theme inputs
"g0_Delinq", "PerfSpell_Num", "TimeInPerfSpell", "slc_acct_roll_ever_24_imputed", "slc_acct_arr_dir_3",
# Credit-themed inputs
"BalanceLog", "InterestRate_Margin", "pmnt_method_grp",
"slc_acct_pre_lim_perc_imputed",  "PD_ratio"
)
datSICR <- subset(datCredit_real, select=varKeep)
# - Cleanup (Memory optimisation)
rm(datCredit_real); gc()
# - Create the SICR-definition based on the parameters [Time-consuming step]
datSICR[, SICR_def := SICR_flag(g0_Delinq, d=p.d, s=p.s), by=list(LoanID)]; gc()
# - Look ahead (over k periods) and assign the SICR-event appropriately for each record
datSICR[, SICR_target := shift(SICR_def, type='lead', n=p.k), by=list(LoanID)]
# - Discard observations where target has NA, implying insufficient history
datSICR <- subset(datSICR, !is.na(SICR_target))
# - Check the event rate of each class | RECORD-LEVEL
table(datSICR$SICR_target) %>% prop.table() # 99.33% Non-SICR vs 0.67% SICR
# - Convert the target variable to a categorical variable for modelling
datSICR[, SICR_target := factor(SICR_target)]; gc()
# - Prepare for resamling scheme
datSICR[, ind := 1:.N]
# - Save to disk (zip) for quick disk-based retrieval later
pack.ffdf(paste0(genPath, "datSICR_", SICR_label), datSICR)
# -- Creating SICR-samples
# - Confirm SICR-dataset is loaded into memory (useful step during interactive execution)
if (!exists('datSICR')) unpack.ffdf(paste0(genPath,"datSICR_", SICR_label), tempPath)
# - Downsample data into a fixed subsample before implementing resampling scheme
smp_size <- 250000; smp_percentage <- smp_size/nrow(datSICR)
set.seed(1)
datSICR_smp <- datSICR %>% group_by(SICR_target, Date) %>% slice_sample(prop=smp_percentage) %>% as.data.table()
# - Join the macros on the filtered dataset to avoid memory constraints
datSICR_smp <- merge_macro_info(input_dat = datSICR_smp)
# - Retain fields based on logit-model corresponding to this definition
varKeep <- c("LoanID", "Date", "Counter", "SICR_target", "ind", "SICR_def",
# Delinquency-theme inputs
"g0_Delinq", "PerfSpell_Num", "TimeInPerfSpell", "slc_acct_roll_ever_24_imputed", "slc_acct_arr_dir_3",
# Credit-themed inputs
"BalanceLog", "InterestRate_Margin", "pmnt_method_grp",
"slc_acct_pre_lim_perc_imputed",  "PD_ratio",
# Macroeconomic-themed inputs
"M_Repo_Rate", "M_Inflation_Growth",
"M_DTI_Growth", "M_DTI_Growth_12"
)
datSICR_smp <- subset(datSICR_smp, select=varKeep)
# - Implement resampling scheme using 70% as sampling fraction
set.seed(1)
datSICR_train <- datSICR_smp %>% group_by(SICR_target, Date) %>% slice_sample(prop=0.7) %>% mutate(Sample="Train") %>% as.data.table()
datSICR_valid <- subset(datSICR_smp, !(ind %in% datSICR_train$ind)) %>% mutate(Sample="Validation")
# - Check representativeness | dataset-level proportions should be similar
table(datSICR_smp$SICR_target) %>% prop.table()
table(datSICR_train$SICR_target) %>% prop.table()
table(datSICR_valid$SICR_target) %>% prop.table()
### RESULTS: Conforms to original proportions, representativeness confirmed
# - cleanup
rm(datSICR); gc()
# - Define model form
inputs_chosen <- SICR_target ~ InterestRate_Margin + BalanceLog + pmnt_method_grp + slc_acct_pre_lim_perc_imputed + TimeInPerfSpell + PD_ratio +
PerfSpell_Num + g0_Delinq + slc_acct_arr_dir_3 + slc_acct_roll_ever_24_imputed + M_Repo_Rate +
M_Inflation_Growth + M_DTI_Growth + M_DTI_Growth_12
# - Save model formula
pack.ffdf(paste0(genObjPath, "SICR_", SICR_label, "_formula_undummified"), inputs_chosen)
# - Fit final logit model
logit_model_chosen <- glm(inputs_chosen, data=datSICR_train, family="binomial")
summary(logit_model_chosen)
# Results first without the inclusion of the PD ratio
# Not all variables are statistically significant
# PD ratio is not statistically significant (p-value of 0.426785 and standard error of 0.0024056)
# - Score data using fitted model
datSICR_train[, Prob_chosen_2a_iii := predict(logit_model_chosen, newdata = datSICR_train, type="response")]
datSICR_valid[, Prob_chosen_2a_iii := predict(logit_model_chosen, newdata = datSICR_valid, type="response")]
datSICR_smp[, ExpProb := predict(logit_model_chosen, newdata = datSICR_smp, type="response")]
# - Compute the AUC
auc(datSICR_train$SICR_target, datSICR_train$Prob_chosen_2a_iii) # 85.66% vs 85.67%
auc(datSICR_valid$SICR_target, datSICR_valid$Prob_chosen_2a_iii) # 84.61% vs 84.63%
auc(datSICR_smp$SICR_target, datSICR_smp$ExpProb) # 85.30% vs 85.31%
# --- 5.2 Plot the density of the class probabilities
# - Graphing parameters
labels.v <- c(bquote(italic(C)[0]),
bquote(italic(C)[1]))
# - Plot double density across both classes
ggplot( data=datSICR_valid, aes(x=Prob_chosen_2a_iii)) + theme_bw() +
geom_histogram(aes(y= ..density.., colour=factor(SICR_target), fill=factor(SICR_target)), alpha=0.7,
bins=2*datSICR_valid[,.N]^(1/3), position="identity") + # using Rice's rule
geom_density(aes(colour=factor(SICR_target), fill=factor(SICR_target)), size=0.8, alpha=0.5) +
labs(x="Class probability", y="Density") +
theme(legend.position="bottom", text=element_text(family=chosenFont)) +
scale_color_brewer(palette="Dark2", name="Class", labels=labels.v) +
scale_fill_brewer(palette="Set2", name="Class", labels=labels.v) +
scale_x_continuous(breaks=pretty_breaks(), label=percent)
# --- 5.3 Find optimal points (c) according to several measures using the training data
# - Set misclassification costs for false positives (FP) and false negatives (FN) respectively
# These are only applicable to cost-sensitive measures later
cost_fp <- 1; cost_fn <- 6
cost_ratio <- cost_fn/cost_fp
# Experimented with [cost_fn] given the underprediction-problem outlined in section 6.3
# Candidates include 40, 10, 6, 7, 8 ; all of whom gave very high overprediction (decreasingly so for lower cost-values).
#  AUC-values remained between 80-83% once discretised.
# Misclassification cost of 8 was propagated to definitions 1a(ii) and 1a(iii)
# Upon this, it was found that the resulting cut-off leads to severe overprediction
# Accordingly, an analysis was conducted to investigate the use of 7 or 6 as the misclassification cost
# The analysis revealed that as k increases, higher misclassification costs result in overprediction
# Since a constant misclassification cost is required over all the definitions, it was decided that 6 yields a good balance across all definitions
# Therefore, final value selected: 6
# - Find optimal cut-offs according to the Generalised Youden's Index measures
# This requires significant memory, which cannot be handled by the current size of the training dataset
optimal.cutpoint.GenYouden <- Gen_Youd_Ind(logit_model_chosen, datSICR_valid, "SICR_target", cost_ratio)
# - Set final cut-off
(logistic_cutoff <- optimal.cutpoint.GenYouden$cutoff)
